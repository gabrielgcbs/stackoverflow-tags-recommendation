{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/thiagoabreulima/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import joblib\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Using Components folder instead of Pages</td>\n",
       "      <td>&lt;p&gt;With Blazor being component based and compo...</td>\n",
       "      <td>directory|architecture|components|blazor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Select data from sqlite3 before or after a cer...</td>\n",
       "      <td>&lt;p&gt;I wan to &lt;strong&gt;select&lt;/strong&gt; the data b...</td>\n",
       "      <td>javascript|database|typescript|sqlite|typeorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Listen to Firebase Firestore data changes for ...</td>\n",
       "      <td>&lt;p&gt;Let's say I have a Firebase firestore datab...</td>\n",
       "      <td>javascript|reactjs|firebase|react-native|googl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to decode a base64 image and getting It's ...</td>\n",
       "      <td>&lt;p&gt;newbie here. I've been working on an image ...</td>\n",
       "      <td>python|tensorflow|machine-learning|base64|fastapi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pods not found while using kubectl port-forward</td>\n",
       "      <td>&lt;p&gt;I want to forward the ports&lt;/p&gt;\\n&lt;pre&gt;&lt;code...</td>\n",
       "      <td>kubernetes|kubectl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0           Using Components folder instead of Pages   \n",
       "1  Select data from sqlite3 before or after a cer...   \n",
       "2  Listen to Firebase Firestore data changes for ...   \n",
       "3  How to decode a base64 image and getting It's ...   \n",
       "4    Pods not found while using kubectl port-forward   \n",
       "\n",
       "                                                body  \\\n",
       "0  <p>With Blazor being component based and compo...   \n",
       "1  <p>I wan to <strong>select</strong> the data b...   \n",
       "2  <p>Let's say I have a Firebase firestore datab...   \n",
       "3  <p>newbie here. I've been working on an image ...   \n",
       "4  <p>I want to forward the ports</p>\\n<pre><code...   \n",
       "\n",
       "                                                tags  \n",
       "0           directory|architecture|components|blazor  \n",
       "1      javascript|database|typescript|sqlite|typeorm  \n",
       "2  javascript|reactjs|firebase|react-native|googl...  \n",
       "3  python|tensorflow|machine-learning|base64|fastapi  \n",
       "4                                 kubernetes|kubectl  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'..//data/raw/bq-results-20220725-121025-1658751889618.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500000 entries, 0 to 499999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   title   500000 non-null  object\n",
      " 1   body    500000 non-null  object\n",
      " 2   tags    499994 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 11.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O dataset possui três atributos, todos do tipo objeto (sendo o atributo *tags*, uma classe).\n",
    "\n",
    "Porém, há amostras com tags vazias, vamos checar quais são."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45182</th>\n",
       "      <td>How to avoid null pointer exception from fires...</td>\n",
       "      <td>&lt;p&gt;I have a firebase application which loads p...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222104</th>\n",
       "      <td>ruby function is returning nil when it should not</td>\n",
       "      <td>&lt;p&gt;I have a written a ruby code that take two ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327727</th>\n",
       "      <td>Map Interface Methods. first things first&lt; I w...</td>\n",
       "      <td>&lt;p&gt;// --------------Map Interface Methods-----...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375230</th>\n",
       "      <td>Nan loss value after few epochs with Contrasti...</td>\n",
       "      <td>&lt;p&gt;I used a Siamese network with contrastive l...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387970</th>\n",
       "      <td>Why is the Button Null?</td>\n",
       "      <td>&lt;p&gt;I'm receiving a NullPointerException. It sa...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394739</th>\n",
       "      <td>Why are NaNs produced for pchisq?</td>\n",
       "      <td>&lt;p&gt;i was using serial.test to check for autoco...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "45182   How to avoid null pointer exception from fires...   \n",
       "222104  ruby function is returning nil when it should not   \n",
       "327727  Map Interface Methods. first things first< I w...   \n",
       "375230  Nan loss value after few epochs with Contrasti...   \n",
       "387970                            Why is the Button Null?   \n",
       "394739                  Why are NaNs produced for pchisq?   \n",
       "\n",
       "                                                     body tags  \n",
       "45182   <p>I have a firebase application which loads p...  NaN  \n",
       "222104  <p>I have a written a ruby code that take two ...  NaN  \n",
       "327727  <p>// --------------Map Interface Methods-----...  NaN  \n",
       "375230  <p>I used a Siamese network with contrastive l...  NaN  \n",
       "387970  <p>I'm receiving a NullPointerException. It sa...  NaN  \n",
       "394739  <p>i was using serial.test to check for autoco...  NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_vazias = df[df['tags'].isna() == True]\n",
    "tags_vazias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round((len(tags_vazias)/len(df))*100, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas elas se tratam de questões específicas de tecnologias/linguagens, portanto o uso de tags seria recomendado nesses casos. Desse modo, como suas tags estão vazias e representam apenas 0.0012% de todas as amostras do dataset, podemos remover essas amostras do banco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 499994 entries, 0 to 499999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   title   499994 non-null  object\n",
      " 1   body    499994 non-null  object\n",
      " 2   tags    499994 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 15.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_sem_vazios = df.dropna()\n",
    "df_sem_vazios.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embora todos os dados sejam textuais, há a possibilidade de haver amostras duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    499994\n",
       "body     499994\n",
       "tags     499994\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sem_duplicados = df_sem_vazios.drop_duplicates()\n",
    "df_sem_duplicados.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os valores da coluna body, por serem escritos originalmente em *Markdown*, possuem caracteres especiais (sequências ASCII) e tags HTML. É interessante removê-las para limpar o corpo das questões, pois esses caracteres e tags não influenciam na questão em si, apenas em sua formatação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sem_duplicados['body'] = df_sem_duplicados['body'].str.replace(r'<[^<>]*>|\\\\', '', regex=True)\n",
    "df_sem_duplicados['body'] = df_sem_duplicados['body'].str.replace(r'\\n', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Using Components folder instead of Pages</td>\n",
       "      <td>With Blazor being component based and componen...</td>\n",
       "      <td>directory|architecture|components|blazor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Select data from sqlite3 before or after a cer...</td>\n",
       "      <td>I wan to select the data before or after a cer...</td>\n",
       "      <td>javascript|database|typescript|sqlite|typeorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Listen to Firebase Firestore data changes for ...</td>\n",
       "      <td>Let's say I have a Firebase firestore database...</td>\n",
       "      <td>javascript|reactjs|firebase|react-native|googl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to decode a base64 image and getting It's ...</td>\n",
       "      <td>newbie here. I've been working on an image cla...</td>\n",
       "      <td>python|tensorflow|machine-learning|base64|fastapi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pods not found while using kubectl port-forward</td>\n",
       "      <td>I want to forward the ports kubectl port-forwa...</td>\n",
       "      <td>kubernetes|kubectl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0           Using Components folder instead of Pages   \n",
       "1  Select data from sqlite3 before or after a cer...   \n",
       "2  Listen to Firebase Firestore data changes for ...   \n",
       "3  How to decode a base64 image and getting It's ...   \n",
       "4    Pods not found while using kubectl port-forward   \n",
       "\n",
       "                                                body  \\\n",
       "0  With Blazor being component based and componen...   \n",
       "1  I wan to select the data before or after a cer...   \n",
       "2  Let's say I have a Firebase firestore database...   \n",
       "3  newbie here. I've been working on an image cla...   \n",
       "4  I want to forward the ports kubectl port-forwa...   \n",
       "\n",
       "                                                tags  \n",
       "0           directory|architecture|components|blazor  \n",
       "1      javascript|database|typescript|sqlite|typeorm  \n",
       "2  javascript|reactjs|firebase|react-native|googl...  \n",
       "3  python|tensorflow|machine-learning|base64|fastapi  \n",
       "4                                 kubernetes|kubectl  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sem_duplicados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Porter Stemmer object for stemming\n",
    "ps = PorterStemmer()\n",
    "#creating the corpus for all the articles\n",
    "corpus = []\n",
    "chunk_size = 10000#Preprocessing\n",
    "\n",
    "for i in range(0,chunk_size):\n",
    "    body = df['body'][i]\n",
    "    title = df['title'][i]\n",
    "    body = body.lower()\n",
    "    title = title.lower()\n",
    "    body = body.split()\n",
    "    title = title.split()\n",
    "    body = [ps.stem(word) for word in body if not word in set(stopwords.words('english')) and len(word) != 1] \n",
    "    title = [ps.stem(word) for word in title if not word in set(stopwords.words('english')) and len(word) != 1] \n",
    "    body = ' '.join(body)\n",
    "    title = ' '.join(title)\n",
    "    paragraph = body + title\n",
    "    corpus.append(paragraph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "df_tags = df_sem_duplicados.copy()\n",
    "all_tags = []\n",
    "\n",
    "for i in range(len(df_tags)):\n",
    "    try:\n",
    "        all_tags.extend(df_tags.tags[i].split('|'))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vectorize = TfidfVectorizer()\n",
    "vectorize.fit(corpus[:5000])#to see the words in the vocabulary use: list(cv.vocabulary_.keys())[:10]#calculate the IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52816"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorize.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [5000, 1439906]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/thiagoabreulima/Desenvolvimento/Workspace/stackoverflow-tags-recommendation/notebooks/if-idf.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/thiagoabreulima/Desenvolvimento/Workspace/stackoverflow-tags-recommendation/notebooks/if-idf.ipynb#ch0000017?line=0'>1</a>\u001b[0m \u001b[39m#WARNING: ALWAYS USE IDF ON A LARGE CORPUS\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/thiagoabreulima/Desenvolvimento/Workspace/stackoverflow-tags-recommendation/notebooks/if-idf.ipynb#ch0000017?line=1'>2</a>\u001b[0m \u001b[39m#tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/thiagoabreulima/Desenvolvimento/Workspace/stackoverflow-tags-recommendation/notebooks/if-idf.ipynb#ch0000017?line=2'>3</a>\u001b[0m \u001b[39m#tfidf_transformer.fit(word_count_vector_train)# do this once, this is a mapping of index \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/thiagoabreulima/Desenvolvimento/Workspace/stackoverflow-tags-recommendation/notebooks/if-idf.ipynb#ch0000017?line=4'>5</a>\u001b[0m clf \u001b[39m=\u001b[39m MLPClassifier(solver\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlbfgs\u001b[39m\u001b[39m'\u001b[39m, alpha\u001b[39m=\u001b[39m\u001b[39m1e-5\u001b[39m, hidden_layer_sizes\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m,\u001b[39m1024\u001b[39m ), random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/thiagoabreulima/Desenvolvimento/Workspace/stackoverflow-tags-recommendation/notebooks/if-idf.ipynb#ch0000017?line=5'>6</a>\u001b[0m clf\u001b[39m.\u001b[39;49mfit(word_count_vector_train,all_tags)\n",
      "File \u001b[0;32m~/anaconda3/envs/mestrado/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:762\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[1;32m    746\u001b[0m     \u001b[39m\"\"\"Fit the model to data matrix X and target(s) y.\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \n\u001b[1;32m    748\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[39m        Returns a trained MLP model.\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 762\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, incremental\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/mestrado/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:394\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhidden_layer_sizes must be > 0, got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m hidden_layer_sizes\n\u001b[1;32m    389\u001b[0m     )\n\u001b[1;32m    390\u001b[0m first_pass \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoefs_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m    391\u001b[0m     \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarm_start \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m incremental\n\u001b[1;32m    392\u001b[0m )\n\u001b[0;32m--> 394\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_input(X, y, incremental, reset\u001b[39m=\u001b[39;49mfirst_pass)\n\u001b[1;32m    396\u001b[0m n_samples, n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[1;32m    398\u001b[0m \u001b[39m# Ensure y is 2D\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mestrado/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1109\u001b[0m, in \u001b[0;36mMLPClassifier._validate_input\u001b[0;34m(self, X, y, incremental, reset)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_input\u001b[39m(\u001b[39mself\u001b[39m, X, y, incremental, reset):\n\u001b[0;32m-> 1109\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m   1110\u001b[0m         X,\n\u001b[1;32m   1111\u001b[0m         y,\n\u001b[1;32m   1112\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   1113\u001b[0m         multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1114\u001b[0m         dtype\u001b[39m=\u001b[39;49m(np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32),\n\u001b[1;32m   1115\u001b[0m         reset\u001b[39m=\u001b[39;49mreset,\n\u001b[1;32m   1116\u001b[0m     )\n\u001b[1;32m   1117\u001b[0m     \u001b[39mif\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1118\u001b[0m         y \u001b[39m=\u001b[39m column_or_1d(y, warn\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/mestrado/lib/python3.8/site-packages/sklearn/base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/envs/mestrado/lib/python3.8/site-packages/sklearn/utils/validation.py:1092\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1075\u001b[0m     X,\n\u001b[1;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1088\u001b[0m )\n\u001b[1;32m   1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m-> 1092\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1094\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/anaconda3/envs/mestrado/lib/python3.8/site-packages/sklearn/utils/validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    385\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    386\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 387\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    390\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5000, 1439906]"
     ]
    }
   ],
   "source": [
    "\n",
    "#WARNING: ALWAYS USE IDF ON A LARGE CORPUS\n",
    "#tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "#tfidf_transformer.fit(word_count_vector_train)# do this once, this is a mapping of index \n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(8,1024 ), random_state=1, verbose=True)\n",
    "clf.fit(word_count_vector_train,all_tags)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mestrado')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55d88438b18c44f5188ac9f14f03406483a2a407ac1e58d3ecc5f0d3f7df8736"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
